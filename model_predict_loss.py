# ุชุญููู ุจูุงูุงุช ุงููุนุจู ุจุงุณุชุฎุฏุงู ุงูุชุนูู ุงูุงูู
#  ุจูุฏู ุงูุชูุจุค ุจุญุงูุฉ ูุฑูุจุฉ ูู ุงูุฎุณุงุฑุฉ ุฃุซูุงุก ุงููุนุจ.
import pandas as pd                         # ุงุณุชูุฑุงุฏ ููุชุจุฉ pandas ููุชุนุงูู ูุน ุงูุจูุงูุงุช
import matplotlib.pyplot as plt             # ูุงุณุชูุฑุงุฏ ุฃุฏูุงุช ุงูุฑุณู ุงูุจูุงูู
from sklearn.tree import plot_tree          # ูุงุณุชูุฑุงุฏ ุฏุงูุฉ ุฑุณู ุดุฌุฑุฉ ุงููุฑุงุฑ

from sklearn.tree import DecisionTreeClassifier    # ุงุณุชูุฑุงุฏ ูููุฐุฌ ุดุฌุฑุฉ ุงููุฑุงุฑ
from sklearn.model_selection import train_test_split  # ูุงุณุชูุฑุงุฏ ุฏุงูุฉ ุชูุณูู ุงูุจูุงูุงุช
from sklearn.metrics import classification_report, accuracy_score  # ูุงุณุชูุฑุงุฏ ุฏูุงู ุชูููู ุงููููุฐุฌ

# ุชุญููู ุงูุจูุงูุงุช ูู ููู CSV
df = pd.read_csv("full_game_data.csv")

# ุฅูุดุงุก ุนููุฏ ุฌุฏูุฏ 'is_near_loss' ูุชุญุฏูุฏ ุงูุญุงูุงุช ุงููุฑูุจุฉ ูู ุงูุฎุณุงุฑุฉ
# ุฅุฐุง ูุงู ุนุฏุฏ ุงูุฎุงูุงุช ุงููุงุฑุบุฉ <= 3 ูุนุชุจุฑ ุงูุญุงูุฉ ูุฑูุจุฉ ูู ุงูุฎุณุงุฑุฉ (1)ุ ูุฅูุง (0)
df['is_near_loss'] = df['EmptyTiles'].apply(lambda x: 1 if x <= 3 else 0)

# ุชุฌููุฒ ุงูููุฒุงุช (ุงููุฏุฎูุงุช) - ุงูุฃุนูุฏุฉ ุงูุชู ูุณุชุฎุฏููุง ุงููููุฐุฌ ููุชูุจุค
X = df[['Score', 'MaxTile', 'MoveTime(ms)', 'EmptyTiles']]

# ุชุฌููุฒ ุงูุนููุฏ ุงููุฏู (ูุง ูุฑูุฏ ุงูุชูุจุค ุจู)
y = df['is_near_loss']

# ุชูุณูู ุงูุจูุงูุงุช ุฅูู ูุฌููุนุฉ ุชุฏุฑูุจ (80%) ูุงุฎุชุจุงุฑ (20%) ูุน ุถุจุท ุงูุนุดูุงุฆูุฉ ููุชุงุฆุฌ ูุชูุฑุฑุฉ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ุฅูุดุงุก ูููุฐุฌ ุดุฌุฑุฉ ุงููุฑุงุฑ ูุน ุชุญุฏูุฏ ุฃูุตู ุนูู ููุดุฌุฑุฉ
model = DecisionTreeClassifier(max_depth=4, random_state=42)

# ุชุฏุฑูุจ ุงููููุฐุฌ ุนูู ุจูุงูุงุช ุงูุชุฏุฑูุจ
model.fit(X_train, y_train)

# ุฑุณู ุดุฌุฑุฉ ุงููุฑุงุฑ ูููู ููููุฉ ุงุชุฎุงุฐ ุงููููุฐุฌ ูููุฑุงุฑุงุช
plt.figure(figsize=(16, 8))  
plot_tree(model, 
          feature_names=['Score', 'MaxTile', 'MoveTime(ms)', 'EmptyTiles'], 
          class_names=['Not Near Loss', 'Near Loss'],
          filled=True)
plt.title("Decision Tree - Near Loss Prediction")
plt.show()

# ุงูุชูุจุค ุจุงุณุชุฎุฏุงู ุงููููุฐุฌ ุนูู ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ
y_pred = model.predict(X_test)

# ุทุจุงุนุฉ ุชูุฑูุฑ ุงูุชุตููู ุงูุฐู ูุญุชูู ุนูู ุฏูุฉ ุงููููุฐุฌ ูุบูุฑูุง ูู ุงูููุงููุณ
print("๐ฏ ุชูุฑูุฑ ุงูุชุตููู:")
print(classification_report(y_test, y_pred))

# ุทุจุงุนุฉ ุฏูุฉ ุงููููุฐุฌ ููุณุจุฉ ูุฆููุฉ
print("โ ุฏูุฉ ุงููููุฐุฌ:", accuracy_score(y_test, y_pred))

import joblib  # ูุงุณุชูุฑุงุฏ ููุชุจุฉ ูุญูุธ ุงููููุฐุฌ ูู ููู

# ุญูุธ ุงููููุฐุฌ ุงููุฏุฑุจ ูู ููู ูุงุณุชุฎุฏุงูู ูุงุญูุงู ุจุฏูู ุงูุญุงุฌุฉ ูุฅุนุงุฏุฉ ุงูุชุฏุฑูุจ
joblib.dump(model, "near_loss_model.pkl")
print("โ ุงููููุฐุฌ ุชู ุญูุธู!")

